# Computation

## Overview of the Importance of Data Computation and Manipulation in Psychological Research

In psychological research, data computation and manipulation are crucial steps that transform raw data into meaningful information. These processes allow researchers to clean, organize, and analyze data effectively, leading to more accurate and reliable conclusions.

## Importance of Data Computation and Manipulation

1.  **Data Cleaning**:

    -   Ensures the accuracy and consistency of data.

    -   Involves identifying and correcting errors, handling missing values, and removing outliers.

    -   Prevents erroneous results that can arise from flawed data.

2.  **Data Organization**:

    -   Facilitates easier analysis and interpretation.

    -   Involves structuring data in a logical format, such as tidy data principles where each variable forms a column and each observation forms a row.

    -   Enhances the readability and usability of the dataset.

3.  **Data Transformation**:

    -   Involves converting data into a suitable format for analysis.

    -   Includes normalization, aggregation, and creating new variables.

    -   Enables the application of various statistical techniques and models.

4.  **Data Exploration**:

    -   Provides insights into data distributions, relationships, and patterns.

    -   Utilizes descriptive statistics and visualization techniques.

    -   Helps in forming hypotheses and guiding further analysis.

5.  **Ensuring Reproducibility**:

    -   Essential for validating and replicating research findings.

    -   Involves documenting and sharing data manipulation steps and analysis scripts.

    -   Enhances transparency and credibility of the research.

By systematically computing and manipulating data, psychological researchers can ensure the integrity of their data, leading to more robust and credible research outcomes.

## Brief Introduction to R's Capabilities for Data Handling

R is a powerful statistical programming language widely used in psychological research for data handling, analysis, and visualization. Its extensive package ecosystem and versatile functions make it an ideal tool for various data manipulation tasks.

### Key Capabilities of R for Data Handling

1.  **Data Importation**:

    -   R can import data from various sources, including CSV files, Excel files, databases, and web APIs.

    -   Functions such as `read.csv()`, `read_excel()`, and `dbConnect()` facilitate data importation.

2.  **Data Cleaning**:

    -   R provides functions to handle missing values (`na.omit()`, `is.na()`), detect and remove outliers, and correct data entry errors.

    -   The `dplyr` package offers a range of functions (`mutate()`, `filter()`, `select()`, `rename()`) for efficient data cleaning.

3.  **Data Transformation**:

    -   R allows for data transformation through functions like `mutate()` for creating new variables, `summarize()` for aggregation, and `spread()`/`gather()` for reshaping data.

    -   The `tidyverse` package is particularly useful for data transformation tasks.

4.  **Data Visualization**:

    -   R supports various visualization techniques through packages like `ggplot2`, `lattice`, and `plotly`.

    -   These packages enable the creation of informative plots such as histograms, scatter plots, and boxplots.

5.  **Statistical Analysis**:

    -   R is equipped with numerous statistical functions and models, including t-tests, ANOVA, regression analysis, and more.

    -   The `stats` package provides foundational statistical functions, while specialized packages like `psych` offer additional tools for psychological research.

6.  **Reproducibility**:

    -   RMarkdown and `knitr` allow for the creation of dynamic documents that integrate code, output, and narrative text.

    -   These tools facilitate reproducible research by enabling researchers to document and share their analysis workflows.

## Importing Data from Excel Files

In psychological research, data is often stored in Excel files, either in CSV (.csv) format or Excel Workbook (.xlsx) format. Importing this data into R is a crucial first step in data analysis. This section covers the process of importing data from both .csv and .xlsx files using R.

### Importing .csv Files

CSV (Comma-Separated Values) files are a common format for storing tabular data. They are simple text files where each line represents a row in the table, and columns are separated by commas.

#### Step-by-Step Guide to Importing .csv Files

1.  **Prepare the CSV File**: Ensure the CSV file is properly formatted with a header row containing column names.

2.  **Set the Working Directory**: Set the working directory in R to the location of the CSV file.

3.  **Use `read.csv()` Function**: Use the `read.csv()` function to read the data into R.

```{r, eval = F}
# Set the working directory to the location of your CSV file
setwd("path/to/your/folder")

# Import the CSV file
data_csv <- read.csv("your_file.csv")

# View the first few rows of the data
head(data_csv)

```

Suppose you have a CSV file named "study_data.csv" containing participant responses to a psychological survey.

```{r, eval = F}
# Set the working directory
setwd("path/to/your/folder")

# Import the CSV file
study_data <- read.csv("study_data.csv")

# View the first few rows of the data
head(study_data)
```

This code sets the working directory, imports the CSV file, and displays the first few rows of the dataset.

### Importing .xlsx Files

Excel Workbook (.xlsx) files are another common format for storing data. They can contain multiple sheets and more complex formatting than CSV files. The `readxl` package in R allows for easy import of .xlsx files.

#### Step-by-Step Guide to Importing .xlsx Files

1.  **Install and Load the `readxl` Package**: If you haven't already installed the `readxl` package, you can do so using `install.packages()`.

2.  **Use `read_excel()` Function**: Use the `read_excel()` function to read the data from the Excel file.

```{r, eval = F}
# Install the readxl package (if not already installed)
install.packages("readxl")

# Load the readxl package
library(readxl)

# Import the Excel file
data_xlsx <- read_excel("path/to/your/file.xlsx")

# View the first few rows of the data
head(data_xlsx)
```

Suppose you have an Excel file named "experiment_data.xlsx" with multiple sheets. You can specify the sheet to read from using the sheet argument.

```{r, eval = F}
# Load the readxl package
library(readxl)

# Import the Excel file, reading from the first sheet by default
experiment_data <- read_excel("experiment_data.xlsx")

# View the first few rows of the data
head(experiment_data)

# Import data from a specific sheet
experiment_data_sheet2 <- read_excel("experiment_data.xlsx", sheet = "Sheet2")

# View the first few rows of the data from Sheet2
head(experiment_data_sheet2)

```

This code demonstrates how to import data from an Excel file and how to read data from a specific sheet within the file.

### Conclusion

Importing data from Excel files into R is a fundamental step in data analysis. Whether dealing with simple CSV files or complex Excel Workbooks, R provides powerful functions to efficiently read and handle this data. In the next section, we will explore techniques for cleaning the imported data to ensure its accuracy and readiness for analysis.

## Cleaning Data

Cleaning data is a crucial step in the data analysis process, ensuring that your data is accurate, consistent, and ready for analysis. The `dplyr` package in R provides a powerful and intuitive set of functions for data manipulation, making it easier to clean and prepare your data.

### Introduction to `dplyr`

`dplyr` is part of the tidyverse, a collection of R packages designed for data science. It provides a set of functions that are specifically designed for data manipulation tasks, including filtering, selecting, mutating, summarizing, arranging data, removing outliers, and releveling categorical factors.

#### Installing and Loading `dplyr`

```{r}
# Install the dplyr package (if not already installed)
if(!require(dplyr)){install.packages("dplyr", dependencies=TRUE)}

# Load the dplyr package
library(dplyr)
```

### Key `dplyr` Functions for Data Cleaning

1.  **`filter()`**: Subset rows based on conditions.

2.  **`select()`**: Select columns by name.

3.  **`rename()`**: Rename columns.

4.  **`mutate()`**: Create new columns or modify existing ones.

5.  **`arrange()`**: Arrange rows by column values.

6.  **`summarize()`**: Summarize multiple values to a single value.

7.  **`group_by()`**: Group data by one or more variables.

8.  **`remove_outliers()`**: Custom function to remove outliers.

9.  **`relevel()`**: Relevel categorical factors for meaningful analysis.

#### 1. `filter()`: Subsetting Rows

The `filter()` function is used to subset rows based on one or more conditions.

**Example**: Filter rows where the age is greater than 30.

```{r}
# Sample data
data <- data.frame(
  id = 1:10,
  age = c(23, 35, 42, 28, 30, 34, 21, 40, 29, 31)
)

# Filter rows where age is greater than 30
filtered_data <- data %>%
  filter(age > 30)

print(filtered_data)
```

#### 2. `select()`: Selecting Columns

The `select()` function is used to select specific columns from a dataset.

**Example**: Select the id and age columns.

```{r}
# Select id and age columns
selected_data <- data %>%
  select(id, age)

print(selected_data)
```

#### 3. `rename()`: Renaming Columns

The `rename()` function is used to rename columns in a dataset.

**Example**: Rename the column `age` to `participant_age`.

```{r}
# Rename age to participant_age
renamed_data <- data %>%
  rename(participant_age = age)

print(renamed_data)
```

#### 4. `mutate()`: Creating or Modifying Columns

The `mutate()` function is used to create new columns or modify existing ones.

**Example**: Create a new column `age_group` based on the age.

```{r}
# Create a new column age_group
mutated_data <- data %>%
  mutate(age_group = ifelse(age > 30, "Above 30", "30 or Below"))

print(mutated_data)
```

#### 5. `arrange()`: Arranging Rows

The `arrange()` function is used to sort rows by column values.

**Example**: Arrange rows by age in descending order.

```{r}
# Arrange rows by age in descending order
arranged_data <- data %>%
  arrange(desc(age))

print(arranged_data)
```

#### 6. `summarize()`: Summarizing Values

The `summarize()` function is used to summarize multiple values into a single value.

**Example**: Calculate the average age.

```{r}
# Calculate the average age
summary_data <- data %>%
  summarize(average_age = mean(age))

print(summary_data)
```

#### 7. `group_by()`: Grouping Data

The `group_by()` function is used to group data by one or more variables, often used in conjunction with `summarize()`.

**Example**: Group data by `age_group` and calculate the average age for each group.

```{r}
# Group by age_group and calculate average age for each group
grouped_data <- mutated_data %>%
  group_by(age_group) %>%
  summarize(average_age = mean(age))

print(grouped_data)
```

#### 8. Removing Outliers

Outliers can skew your analysis and lead to misleading results. Removing outliers helps in obtaining a more accurate representation of the data.

**Example**: Removing outliers based on the IQR method.

```{r}
# Custom function to remove outliers
remove_outliers <- function(data, column) {
  Q1 <- quantile(data[[column]], 0.25)
  Q3 <- quantile(data[[column]], 0.75)
  IQR <- Q3 - Q1
  lower_bound <- Q1 - 1.5 * IQR
  upper_bound <- Q3 + 1.5 * IQR
  data <- data %>%
    filter(data[[column]] >= lower_bound & data[[column]] <= upper_bound)
  return(data)
}

# Remove outliers from the age column
data_no_outliers <- remove_outliers(data, "age")

print(data_no_outliers)
```

#### 9. Releveling Categorical Factors

Releveling categorical factors ensures that the reference level is meaningful for your analysis. This is particularly important in regression models where the reference level serves as the baseline.

**Example**: Relevel the `age_group` column to set "30 or Below" as the reference level.

```{r}
# Relevel age_group to set "30 or Below" as the reference level
mutated_data <- mutated_data %>%
  mutate(age_group = relevel(factor(age_group), ref = "30 or Below"))

print(mutated_data)
```

### Practical Examples of Data Cleaning

Combining multiple `dplyr` functions can make complex data cleaning tasks straightforward.

**Example 1**: Cleaning a Survey Dataset

```{r}
# Sample survey data
survey_data <- data.frame(
  id = 1:10,
  age = c(23, 35, 42, NA, 30, 34, 21, 40, 29, 31),
  gender = c("M", "F", "F", "M", "M", "F", "M", "F", "M", "F"),
  score = c(80, 85, 78, 90, 85, 75, 88, 92, 84, NA)
)

# Clean the survey data
cleaned_survey_data <- survey_data %>%
  # Remove rows with missing values
  filter(!is.na(age), !is.na(score)) %>%
  # Rename columns
  rename(participant_age = age, test_score = score) %>%
  # Create age_group column
  mutate(age_group = ifelse(participant_age > 30, "Above 30", "30 or Below")) %>%
  # Remove outliers in test_score
  remove_outliers("test_score") %>%
  # Select relevant columns
  select(id, participant_age, gender, age_group, test_score) %>%
  # Arrange by test_score in descending order
  arrange(desc(test_score))

print(cleaned_survey_data)
```

**Example 2**: Cleaning Experimental Data

```{r}
# Sample experimental data
experiment_data <- data.frame(
  subject_id = 1:15,
  condition = rep(c("Control", "Treatment"), length.out = 15),
  response_time = c(200, 150, 250, 300, 220, 180, 290, 310, 205, 190, 175, 265, 225, 230, 210)
)

# Clean the experimental data
cleaned_experiment_data <- experiment_data %>%
  # Filter out response times greater than 300 ms
  filter(response_time <= 300) %>%
  # Calculate mean response time by condition
  group_by(condition) %>%
  summarize(mean_response_time = mean(response_time)) %>%
  # Relevel the condition factor to set Control as the reference level
  mutate(condition = relevel(factor(condition), ref = "Control")) %>%
  # Arrange by mean_response_time
  arrange(mean_response_time)

print(cleaned_experiment_data)
```

### Conclusion

Cleaning data is a vital step in ensuring the accuracy and reliability of your analysis. The `dplyr` package in R provides a suite of powerful functions to simplify and streamline this process, including removing outliers and releveling categorical factors. By mastering these functions, you can efficiently manipulate and prepare your data for analysis, leading to more robust and credible research outcomes. In the next section, we will explore techniques for describing data using the `psych` package, providing practical examples and hands-on exercises.

## Describing Data Using the `psych` Package

### Overview of the `psych` Package

The `psych` package in R is designed to facilitate psychological research by providing tools for data analysis, including descriptive statistics, reliability analysis, and factor analysis. This package is widely used for its comprehensive functions that cater specifically to the needs of psychological researchers.

#### Introduction to the `psych` Package and its Functionalities

The `psych` package offers various functions to perform:

1.  **Descriptive Statistics**: Summarize data with measures such as mean, median, variance, standard deviation, and more.

2.  **Reliability Analysis**: Assess the reliability of scales and measurements.

3.  **Factor Analysis**: Conduct exploratory and confirmatory factor analysis.

4.  **Graphical Representations**: Create visual summaries of data, including correlation matrices and pair panels.

#### Installation and Loading the Package

To use the `psych` package, you need to install it (if not already installed) and then load it into your R session.

```{r}
if(!require(psych)){install.packages("psych", dependencies=TRUE)}
library(psych)
```

### Descriptive Statistics with `psych`

Generating descriptive statistics is a fundamental part of data analysis, providing insights into the central tendency, variability, and distribution of your data.

#### Techniques for Generating Descriptive Statistics

The `describe()` function in the `psych` package is a powerful tool for generating a comprehensive summary of your dataset. It provides various descriptive statistics, including:

-   Mean

-   Standard deviation

-   Median

-   Minimum and maximum values

-   Range

-   Skewness and kurtosis

#### Practical Example with Sample Data

Let's consider a dataset of participants' test scores.

```{r}
# Sample data
test_scores <- data.frame(
  id = 1:10,
  score = c(85, 90, 78, 92, 88, 76, 95, 89, 84, 91)
)

# Generate descriptive statistics
describe(test_scores)
```

This code generates a detailed summary of the `test_scores` dataset, providing a comprehensive overview of its statistical properties.

### Graphical Representations with `psych`

Creating graphical summaries is essential for visualizing data patterns and relationships. The `psych` package provides several functions for this purpose.

#### Techniques for Creating Graphical Summaries

1.  **Correlation Matrix Visualization**: The `corPlot()` function visualizes the correlation matrix of a dataset.

2.  **Pair Panels**: The `pairs.panels()` function creates scatterplot matrices with histograms and correlation coefficients.

#### Practical Example

Let's visualize the relationships between multiple variables in a dataset.

```{r}
# Sample data
multi_var_data <- data.frame(
  score = c(85, 90, 78, 92, 88, 76, 95, 89, 84, 91),
  age = c(23, 25, 22, 24, 26, 21, 27, 25, 23, 24),
  study_hours = c(5, 6, 4, 6, 5, 3, 7, 6, 5, 6)
)

# Visualize the correlation matrix
corPlot(cor(multi_var_data), numbers = TRUE, main = "Correlation Matrix")

```

#### Reading the `corPlot()` Output

The `corPlot()` function generates a visual representation of the correlation matrix for a dataset. Here's how to interpret the different elements of the output:

1.  **Correlation Coefficients**: The numerical values in the matrix represent the correlation coefficients between pairs of variables. These coefficients quantify the strength and direction of the linear relationship between variables.

    -   **Correlation Coefficient (r)**: The value ranges from -1 to 1.

        -   **r = 1**: Perfect positive correlation.

        -   **r = -1**: Perfect negative correlation.

        -   **r = 0**: No correlation.

2.  **Color Coding**: The cells in the matrix are color-coded to reflect the strength and direction of the correlations.

    -   **Positive Correlations**: Shades of blue indicate positive correlations, with darker shades representing stronger correlations.

    -   **Negative Correlations**: Shades of red indicate negative correlations, with darker shades representing stronger negative correlations.

3.  **Significance Levels**: If the `numbers` argument is set to `TRUE`, the plot displays the correlation coefficients as numbers within the cells, helping you to identify the exact strength of each correlation.

**Example Output Interpretation**:

-   **Diagonal Elements**: The diagonal elements of the matrix represent the correlation of each variable with itself, which is always 1.

-   **Off-Diagonal Elements**: The off-diagonal elements show the correlation coefficients between pairs of variables. For instance, a cell showing a value of 0.75 between `study_hours` and `score` indicates a strong positive correlation.

-   **Color Coding**: If a cell is dark blue, it signifies a strong positive correlation, whereas a dark red cell signifies a strong negative correlation. Light colors indicate weaker correlations.

-   **Numerical Values**: The numbers within the cells provide the exact correlation coefficients, making it easy to identify and interpret the strength of the relationships.

-   **Correlation between `score` and `study_hours`**: The correlation coefficient might be 0.75, displayed in a dark blue cell, indicating a strong positive correlation.

-   **Correlation between `score` and `age`**: The correlation coefficient might be 0.30, displayed in a light blue cell, indicating a moderate positive correlation.

-   **Correlation between `age` and `study_hours`**: The correlation coefficient might be -0.15, displayed in a light red cell, indicating a weak negative correlation.

These interpretations help you understand how the variables in your dataset relate to one another, guiding further analysis and decision-making.

```{r Create pair panels}
pairs.panels(multi_var_data, 
             method = "pearson",  # correlation method
             hist.col = "blue",    # histogram color
             density = TRUE,       # add density plots
             ellipses = TRUE       # add correlation ellipses
)

```

The `corPlot()` function displays a correlation matrix with correlation coefficients, while `pairs.panels()` creates a scatterplot matrix with histograms and density plots, providing a detailed visual summary of the relationships between variables.

#### Reading the `pairs.panels()` Output

The `pairs.panels()` function generates a comprehensive visual summary of the relationships between multiple variables in a dataset. Here's how to interpret the different elements of the output:

1.  **Scatterplots (Lower Triangle)**: The lower triangle of the matrix contains scatterplots for each pair of variables. Each scatterplot shows the relationship between two variables, allowing you to visually assess the strength and direction of their correlation.

    -   **Positive Correlation**: If the points in the scatterplot form an upward sloping pattern, it indicates a positive correlation between the variables.

    -   **Negative Correlation**: If the points form a downward sloping pattern, it indicates a negative correlation.

    -   **No Correlation**: If the points are widely scattered with no discernible pattern, it suggests little to no correlation.

2.  **Histograms (Diagonal)**: The diagonal of the matrix contains histograms for each variable. These histograms show the distribution of values for each variable, helping you to understand their central tendency, variability, and skewness.

    -   **Symmetric Distribution**: A bell-shaped histogram suggests a normal distribution.

    -   **Skewed Distribution**: A histogram with a long tail on one side indicates skewness in the data.

3.  **Correlation Coefficients (Upper Triangle)**: The upper triangle of the matrix contains correlation coefficients for each pair of variables. These coefficients quantify the strength and direction of the linear relationship between variables.

    -   **Correlation Coefficient (r)**: The value ranges from -1 to 1.

        -   **r = 1**: Perfect positive correlation.

        -   **r = -1**: Perfect negative correlation.

        -   **r = 0**: No correlation.

    -   **Significance Levels**: The size and color of the coefficients may indicate the significance level, helping you to identify which correlations are statistically significant.

4.  **Density Plots (Lower Triangle, if `density = TRUE`)**: If the `density` argument is set to `TRUE`, density plots will be overlaid on the scatterplots. These plots show the density of data points, providing additional insight into the distribution of values.

5.  **Correlation Ellipses (Lower Triangle, if `ellipses = TRUE`)**: If the `ellipses` argument is set to `TRUE`, ellipses will be drawn on the scatterplots. These ellipses represent confidence intervals for the correlation, helping you to visually assess the strength and direction of the relationship.

-   **Scatterplots**: You might see an upward slope between `study_hours` and `score`, indicating a positive correlation where increased study hours are associated with higher scores.

-   **Histograms**: The histogram for `age` might show a relatively uniform distribution, while the histogram for `study_hours` could indicate most participants study between 4 to 6 hours.

-   **Correlation Coefficients**: The coefficient between `score` and `study_hours` might be 0.75, suggesting a strong positive correlation. The coefficient between `age` and `score` might be lower, indicating a weaker relationship.

-   **Density Plots**: Overlaid on the scatterplots, these provide additional information about the concentration of data points.

-   **Correlation Ellipses**: Ellipses around the scatterplots indicate the confidence intervals, with tighter ellipses suggesting stronger correlations.

### Conclusion

The `psych` package in R offers a comprehensive set of tools for describing and visualizing data, making it invaluable for psychological research. By using functions like `describe()` for descriptive statistics and `pairs.panels()` for graphical representations, researchers can gain deeper insights into their data. In the next section, we will explore techniques for importing data from various sources and preparing it for analysis.

## Chapter Summary

This chapter provided a comprehensive guide on the essential tasks involved in data computation and manipulation, focusing on the techniques and tools necessary for psychological research. We explored importing data, cleaning data using the `dplyr` package, and describing data using the `psych` package, each accompanied by detailed explanations and practical examples.

### Key Points Recap

1.  **Importance of Data Computation and Manipulation**:

    -   Data computation and manipulation are critical steps in ensuring that data is accurate, consistent, and ready for analysis.

    -   These processes allow researchers to clean, organize, and analyze data effectively, leading to more reliable and meaningful conclusions.

2.  **Importing Data from Excel Files**:

    -   We covered how to import data from both CSV (.csv) and Excel Workbook (.xlsx) files.

    -   Using `read.csv()` for CSV files and the `readxl` package for Excel files, we demonstrated practical examples to ensure seamless data importation.

3.  **Cleaning Data with `dplyr`**:

    -   The `dplyr` package provides powerful and intuitive functions for data manipulation tasks.

    -   Key functions include `filter()`, `select()`, `rename()`, `mutate()`, `arrange()`, `summarize()`, and `group_by()`.

    -   We also covered removing outliers using a custom function and releveling categorical factors for meaningful analysis.

    -   Practical examples illustrated how to apply these functions to clean and prepare data for analysis.

4.  **Describing Data Using the `psych` Package**:

    -   The `psych` package offers tools for generating descriptive statistics and creating graphical summaries.

    -   Using the `describe()` function, we generated comprehensive summaries of datasets.

    -   The `pairs.panels()` function was used to create scatterplot matrices with histograms and correlation coefficients, providing detailed visual summaries of data relationships.

    -   The `corPlot()` function was used to visualize correlation matrices, with detailed explanations on how to interpret the output.

### Practical Applications

Throughout the chapter, practical examples demonstrated how to:

-   Import data from various file formats.

-   Clean and prepare data using `dplyr`, including handling missing values, renaming variables, removing outliers, and releveling factors.

-   Generate descriptive statistics and visualize data using the `psych` package, including scatterplot matrices and correlation plots.

### Conclusion

This chapter highlighted the importance of data computation and manipulation in psychological research. By mastering these techniques and tools, researchers can ensure that their data is well-prepared and accurately analyzed, leading to more robust and credible research outcomes. The knowledge and skills acquired in this chapter lay the foundation for more advanced data analysis techniques covered in subsequent chapters.

## Practice Exercises

These exercises aim to test your understanding of data importation, cleaning, and descriptive analysis using the `dplyr` and `psych` packages in R. You will apply these concepts to practical problems, ensuring you can efficiently manipulate and describe data.

### Exercise 1: Importing Data

-   **Task**: Import data from a CSV file and an Excel file.

-   **Instructions**:

    1.  Create a CSV file named `survey_data.csv` with the following columns: `id`, `age`, `gender`, `score`.

    2.  Create an Excel file named `experiment_data.xlsx` with the following columns: `subject_id`, `condition`, `response_time`.

    3.  Import both files into R.


### Exercise 2: Cleaning Data with `dplyr`

-   **Task**: Clean a dataset using various `dplyr` functions.

-   **Instructions**:

    1.  Use the following dataset for the exercise:


```{r}
data <- data.frame(
  id = 1:10,
  age = c(23, 35, 42, NA, 30, 34, 21, 40, 29, 31),
  gender = c("M", "F", "F", "M", "M", "F", "M", "F", "M", "F"),
  score = c(80, 85, 78, 90, 85, 75, 88, 92, 84, NA)
)
```

    2.  Clean the dataset by performing the following steps:

        -   Remove rows with missing values.

        -   Rename the `age` column to `participant_age`.

        -   Create a new column `age_group` based on `participant_age` (Above 30 or 30 and Below).

        -   Remove outliers from the `score` column.

        -   Relevel the `age_group` column to set "30 and Below" as the reference level.


### Exercise 3: Generating Descriptive Statistics with `psych`

-   **Task**: Generate descriptive statistics for a dataset.

-   **Instructions**:

    1.  Use the following dataset for the exercise:

```{r}
test_scores <- data.frame(
  id = 1:10,
  score = c(85, 90, 78, 92, 88, 76, 95, 89, 84, 91)
)
```


    2.  Generate descriptive statistics using the `describe()` function from the `psych` package.


### Exercise 4: Visualizing Data with `psych`

-   **Task**: Create graphical summaries of a dataset using the `psych` package.

-   **Instructions**:

    1.  Use the following dataset for the exercise:

```{r}
multi_var_data <- data.frame(
  score = c(85, 90, 78, 92, 88, 76, 95, 89, 84, 91),
  age = c(23, 25, 22, 24, 26, 21, 27, 25, 23, 24),
  study_hours = c(5, 6, 4, 6, 5, 3, 7, 6, 5, 6)
)
```


    2.  Create a correlation plot using the `corPlot()` function.

    3.  Create pair panels using the `pairs.panels()` function.

# Interactions in Regression Models

## Introduction to Interactions

### What Are Interactions?

In regression models, an **interaction** occurs when the effect of one variable on the outcome depends on the level of another variable. In simpler terms, interactions happen when the relationship between two variables is not straightforward but instead changes depending on another factor.

For example, let's say you're studying how a new therapy affects anxiety levels. You might find that the therapy is effective in reducing anxiety, but the effect of the therapy might be different for men compared to women. This difference means there's an interaction between gender and the therapy---the impact of the therapy depends on whether the person is male or female.

In psychological research and many other fields, interactions are crucial because they help us understand the combined effects of variables. Without considering interactions, we might overlook important differences in how variables influence outcomes across different groups or conditions.

**Real-World Example:** Consider a study on how different types of support (e.g., emotional vs. practical) influence recovery from illness. The effectiveness of each type of support might depend on the patient's age. Younger patients might benefit more from emotional support, while older patients might find practical support more beneficial. This situation shows an interaction between the type of support and the patient's age.

### Why Are Interactions Important?

Interactions are significant because they allow us to understand how variables work together to influence an outcome. In many cases, the effect of one variable isn't uniform across all conditions---it might vary depending on another variable. By modeling interactions, we can gain a deeper and more accurate understanding of the relationships between variables.

For instance, in psychological research, you might be interested in how stress affects health. However, the impact of stress on health could depend on the level of social support a person has. People with high levels of social support might cope with stress better, leading to less negative health outcomes, while those with low social support might experience more severe effects of stress. This interaction between stress and social support reveals a more nuanced understanding of how these factors work together.

Interactions can also uncover relationships that aren't apparent when looking at variables independently. Without considering interactions, you might miss important insights, such as understanding why a treatment works well for one group but not another, or why a certain behavior leads to different outcomes in different contexts.

**Examples in Psychological Research:**

\- **Stress and Support:** How stress interacts with social support to influence health outcomes.

\- **Treatment and Gender:** How the effectiveness of a treatment varies by gender.

\- **Age and Learning:** How the impact of a learning method differs across age groups.

Understanding interactions helps researchers and practitioners make more informed decisions and tailor interventions more effectively to different groups or conditions. By examining how variables interact, we can better predict outcomes and understand the complexities of human behavior and experiences.

## Categorical x Categorical Interactions

### Understanding Categorical x Categorical Interactions

Categorical x categorical interactions occur when the effect of one categorical variable on the outcome depends on the level of another categorical variable. In other words, the influence of one factor is not consistent across all levels of another factor.

To make this clear, let's use a real-world example. Suppose you're studying how different types of treatment (e.g., Medication A and Medication B) affect recovery rates in patients. Additionally, you want to see if this effect is different for men and women. Here, both **gender** (male, female) and **treatment type** (Medication A, Medication B) are categorical variables.

A **categorical x categorical interaction** would examine how the combination of these two variables influences recovery rates. For instance, Medication A might be more effective for men, while Medication B might work better for women. This difference in effectiveness indicates an interaction between gender and treatment type.

#### Modeling Categorical x Categorical Interactions

To include a categorical x categorical interaction in a regression model, we need to create an interaction term between the two categorical variables. When working with categorical variables in regression, it's common to use **effect coding** instead of the default dummy coding. Effect coding is particularly useful because it centers the variables, making the interpretation of the main effects more intuitive.

**Effect coding** assigns values of -0.5 and 0.5 to the levels of a categorical variable. For example, if we have a variable for gender, we can code males as -0.5 and females as 0.5. Similarly, for treatment type, we might code Medication A as -0.5 and Medication B as 0.5.

Here's how you can model the interaction between gender and treatment type in R:

```{r}
library(ggplot2)

# Increase the sample size with more extreme group differences
set.seed(123) # For reproducibility

# Generate data for 50 males and 50 females
Gender <- factor(rep(c("Male", "Female"), each = 50))
Treatment <- factor(rep(c("A", "B"), each = 25, times = 2))

# Assign more extreme recovery rates with random noise added
Recovery <- c(
  rnorm(25, mean = 60, sd = 5),  # Male, Treatment A
  rnorm(25, mean = 90, sd = 5),  # Male, Treatment B
  rnorm(25, mean = 70, sd = 5),  # Female, Treatment A
  rnorm(25, mean = 50, sd = 5)   # Female, Treatment B
)

# Create a data frame
data <- data.frame(Gender, Treatment, Recovery)

# Apply effect coding
data$Gender_Effect <- ifelse(data$Gender == "Male", -0.5, 0.5)
data$Treatment_Effect <- ifelse(data$Treatment == "A", -0.5, 0.5)

# Fit the regression model with interaction
model <- lm(Recovery ~ Gender_Effect * Treatment_Effect, data = data)

# Display the model summary
summary(model)
```

To further explore the significant differences between the groups, we can perform post hoc tests after fitting the regression model. Post hoc tests allow us to compare the means of different groups to see which specific group differences are statistically significant.

### Step-by-Step Guide to Adding Post Hoc Tests

#### Post Hoc Tests Using `emmeans`

We can use the `emmeans` package to perform post hoc comparisons. This package allows us to estimate the marginal means (also known as least-squares means) and conduct pairwise comparisons between groups.

First, we need to load the `emmeans` package (or install first it if it is not already installed):

```{r}
library(emmeans)
```

**Estimating Marginal Means and Performing Pairwise Comparisons**

After fitting the model, we can estimate the marginal means for each group and perform pairwise comparisons to see which group differences are statistically significant.

```{r}
# Re-create the model using the categorical variables (it makes it easier to interpret)
model_cat <- lm(Recovery ~ Gender * Treatment, data = data)

# Estimate marginal means (emmeans) for the interaction of Gender and Treatment
emmeans_model <- emmeans(model_cat, ~ Gender * Treatment)

# Display the estimated marginal means
emmeans_model

# Perform pairwise comparisons (post hoc tests) with Tukey adjustment for multiple comparisons
pairwise_comparisons <- pairs(emmeans_model, adjust = "tukey")

# Display the pairwise comparisons
pairwise_comparisons
```

#### Interpretation of Post Hoc Test Results

-   **Estimated Marginal Means (emmeans)**:
    -   The `emmeans` output shows the mean recovery rates for each combination of gender and treatment type, adjusted for the other variables in the model.
-   **Pairwise Comparisons**:
    -   The `pairs()` function provides the pairwise comparisons between the different levels of gender and treatment.
    -   The **p-values** indicate whether the difference between the means of two groups is statistically significant.
    -   The Tukey adjustment controls for the increased risk of Type I error due to multiple comparisons.

For example, the pairwise comparisons might show:

-   **Male with Treatment A vs. Male with Treatment B**: A significant difference, indicating that Treatment B is significantly more effective for males.
-   **Female with Treatment A vs. Female with Treatment B**: A significant difference, indicating that Treatment A is significantly more effective for females.
-   **Male with Treatment A vs. Female with Treatment A**: A significant difference, showing that the effectiveness of Treatment A differs significantly by gender.
-   **Male with Treatment B vs. Female with Treatment B**: A significant difference, showing that the effectiveness of Treatment B differs significantly by gender.

### Visualizing the Results with Error Bars

We can also visualize the results, including confidence intervals, to further interpret the significant differences:

```{r}
# Plot the interaction with error bars
ggplot(means, aes(x = Treatment, y = Recovery, fill = Gender)) +
  geom_bar(stat = "identity", position = "dodge") +
  geom_errorbar(aes(ymin = Recovery - 2*5/sqrt(25), ymax = Recovery + 2*5/sqrt(25)),
                width = 0.2, position = position_dodge(0.9)) +
  labs(title = "Interaction between Gender and Treatment on Recovery Rates",
       x = "Treatment Type", y = "Mean Recovery Rate with 95% CI") +
  scale_fill_manual(values = c("Male" = "lightblue", "Female" = "lightcoral")) +
  theme_minimal()
```

-   **Error Bars**: Represent the 95% confidence intervals around the estimated means. If the error bars for two groups do not overlap, this typically indicates a statistically significant difference between those groups.

### Conclusion

With these post hoc tests, you can clearly identify which specific group differences are statistically significant. The combination of the `emmeans` package for pairwise comparisons and visualizations with error bars helps to thoroughly explore and interpret the interaction effects in your data.

Using bar graphs to visualize categorical x categorical interactions is a powerful way to clearly communicate the combined effects of variables. It allows for an easy comparison of group means and helps in understanding how different combinations of variables influence the outcome.

## Linear x Linear Interactions

### Understanding Linear x Linear Interactions

**Linear x linear interactions** occur when the relationship between two continuous (linear) variables changes depending on the level of another continuous variable. In other words, the effect of one variable on an outcome isn’t the same across all levels of another variable—it varies depending on the values of both variables.

Let’s break this down with an example. Imagine you are studying how **age** and **education level** influence **cognitive performance**. Both age and education level are continuous variables. You might find that the effect of age on cognitive performance changes depending on the level of education. For instance, age might have a more pronounced negative effect on cognitive performance for individuals with lower education levels, while for those with higher education levels, age might have a smaller or even no effect.

This scenario illustrates a **linear x linear interaction**: the effect of age on cognitive performance is not constant but changes depending on education level.

### Modeling Linear x Linear Interactions

To include a linear x linear interaction in a regression model, we create an interaction term between the two continuous variables. This interaction term allows us to see how the relationship between one variable and the outcome changes as the other variable changes.

**Step-by-Step Guide to Modeling Linear x Linear Interactions:**

Let’s say we want to model the interaction between **age** and **education** on **cognitive performance**. Here’s how you can do this in R:

1. **Create the dataset**:

```{r}
   # Simulating data
   set.seed(123)
   Age <- rnorm(100, mean = 50, sd = 10)       # Continuous variable: Age
   Education <- rnorm(100, mean = 16, sd = 3)  # Continuous variable: Years of Education
   Cognitive_Performance <- 100 - 0.5 * Age + 1.5 * Education + 0.1 * Age * Education + rnorm(100, sd = 5)

   # Create a data frame
   data <- data.frame(Age, Education, Cognitive_Performance)
```

   In this simulated data:
   - **Age**: Represents the age of the individuals.
   - **Education**: Represents the number of years of education.
   - **Cognitive_Performance**: A score representing cognitive performance.

2. **Fit the regression model with the interaction term**:

```{r}
   # Fit the regression model with an interaction term between Age and Education
   model <- lm(Cognitive_Performance ~ Age * Education, data = data)

   # Display the model summary
   summary(model)
```

   - The model includes the main effects of both Age and Education, as well as their interaction (Age * Education).
   - **Main effects**: Show how each variable (Age and Education) affects cognitive performance individually.
   - **Interaction term (Age:Education)**: Shows how the effect of Age on cognitive performance changes depending on the level of Education, and vice versa.

**Interpreting Interaction Terms:**

- **Main Effects (Age and Education)**:
  - **Age**: Represents the average effect of age on cognitive performance, holding education constant.
  - **Education**: Represents the average effect of education on cognitive performance, holding age constant.

- **Interaction Term (Age:Education)**:
  - This term tells us how the relationship between age and cognitive performance changes at different levels of education. If the interaction term is significant, it suggests that the effect of age on cognitive performance varies depending on the level of education.

### Visualizing Linear x Linear Interactions

Visualizing linear x linear interactions can be done in a few different ways, depending on the complexity of the data and the message you want to convey.

**Option 1: 3D Surface Plot**

A 3D surface plot allows you to visualize the interaction between two continuous variables in a way that shows how the outcome variable changes across the full range of both predictors.

Here’s how to create a 3D plot in R:

```{r}
# Install and load the rgl package for 3D plotting
install.packages("rgl")
library(rgl)

# Create a 3D scatter plot with a surface
plot3d(data$Age, data$Education, data$Cognitive_Performance,
       xlab = "Age", ylab = "Education", zlab = "Cognitive Performance",
       col = "blue", size = 3)

```

- **3D Scatter Plot**: Shows individual data points in a 3D space, with Age on the x-axis, Education on the y-axis, and Cognitive Performance on the z-axis.
- **Surface**: Represents the predicted values of Cognitive Performance from the model, allowing you to see how performance changes with age and education.

**Option 2: 2D Plot by Splitting One Variable**

For a simpler visualization, you can split one of the continuous variables into categories (e.g., high vs. low) and create a 2D plot with lines representing the interaction.

Here’s how to create a 2D plot by splitting Education into high and low groups:

```{r}
# Create a new variable to categorize Education into High and Low
data$Education_Level <- ifelse(data$Education > median(data$Education), "High", "Low")

# Plot Cognitive Performance vs. Age, colored by Education Level
ggplot(data, aes(x = Age, y = Cognitive_Performance, color = Education_Level)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) +
  labs(title = "Interaction between Age and Education on Cognitive Performance",
       x = "Age", y = "Cognitive Performance") +
  scale_color_manual(values = c("High" = "darkorange", "Low" = "steelblue")) +
  theme_minimal()
```

**Interpreting the 2D Plot**:

- **Lines**: Represent the relationship between Age and Cognitive Performance for individuals with High and Low levels of Education.
- **Interaction**: If the slopes of the lines differ, it indicates an interaction—meaning the effect of Age on Cognitive Performance changes depending on whether someone has high or low education.

### Conclusion

Linear x linear interactions provide a way to understand how the relationship between two continuous variables affects an outcome. By modeling and visualizing these interactions, you can uncover complex relationships in your data that wouldn’t be apparent by looking at each variable in isolation.
